Neuroimaging, a field focused on understanding structure and function within the brain, has evolved into a
discipline of computational science. In recent years, through the collection and evaluation of rich and
descriptive datasets, countless studies have explored the possible utility of these images and began the
development of relationships between them and phenotypic information such as disease, sex, stage of development,
and more. Like many modern scientific disciplines, however, the robustness and generalizability of these
relationships depends on the trustworthiness of the methods used in their generation. With an increasing
awareness on issues of reproducibility in science, preliminary explorations in neuroimaging have led to some
skepticism regarding the robustness of findings. While impactful differences have been observed across
scientific teams, methods, toolboxes, or even the operating system of the computer being used, no studies
have enabled or characterized the effect that unavoidable machine error has on this variability. Throughout
this thesis I have developed infrastructure for high performance computing environments to enable the large
scale numerical analysis of neuroimaging experiments, and used it to evaluate the role that numerical
uncertainty in computing plays in the reproducibility or stability of results. Focusing on the application of
mapping connections between brain regions, called structural connectomics, I perturbed the generation of
networks and subsequently evaluated the observed variability to characterize the impact of small numerical
errors as they accumulate over the course of an analysis. I found that not only do unavoidable computational
errors have a considerable impact on results, but that they can in some cases be so significant as to obscure
individual differences in maps of connectivity. This finding importantly demonstrates a best-case bound of
error and its propagation throughout scientific pipelines. Moving beyond the perturbation of error, efforts to
interpret the observed variability as a feature of a given analysis rather than a bug showed that not only did
this variability increase the reliability of datasets, but it ultimately could be harnessed to produce stronger
and more generalizable brain-phenotype relationships. The combination of these results importantly demonstrates
that unavoidable computational errors inherent to pipelines lead to impactful differences in a set of
neuroimaging analyses. Whether that impact is for better or worse, however, depends entirely on whether these
errors are being considered and accounted for, or ignored. Alongside the execution of these analyses, this
thesis presents tools and a schematic which can be followed for the further exploration of numerical
uncertainty and the role it may play in our understanding of the brain.




